# Operating System



# 목차

- [운영체제란 무엇인가](#운영체제란-무엇인가)





# 운영체제란 무엇인가

가장 간단하게 말하자면, 운영체제라는 컴퓨터의 하드웨어를 관리하는 프로그램이다. 컴퓨터는 하드웨어만 있다고 동작하지 않는다. 하드웨어 위에서 소프트웨어가 동작하는데, 이때 소프트웨어들은 하드웨어의 자원들을 사용할 필요가 있다. 이때 운영체제가 필요하다. 운영체제는 소프트웨어에게 하드웨어의 자원들을 어떻게 분배할 것인가? 에 대한 프로그램이다.

**OS is a resource allocator** 즉, OS는 컴퓨터의 모든 자원을 관리하고, 자원을 효율적으로 공평하게 사용하기 위해 누구에게 자원을 할당할 것인지 결정하는 프로그램이다.

### Interrupt Driven

CPU와 I/O 장치들은 동시적으로 작동한다. 
 I/O장치들은 장치 컨트롤러 (Device Controller)라는것이 존재하고, 그 안에 Local Buffer가 존재한다. I/O란 Device와 Device Controller간의 데이터 전달이다. 
**Input이란** Device에서 Device Controller의 지역 버퍼로 데이터가 옮겨지는 과정이고, **Output이란** Device Controller에서 Device로 데이터가 옮겨지는 과정이다. 
이후 Device Controller에서 I/O작업이 끝나면 CPU에게 Interrupt를 발생시키고, 이 후에 CPU는 해당 Interrupt를 처리하기 위해 작동하게되는것이다. 
그렇기 때문에 CPU가 I/O작업을 위해 기다리는것은 매우 비효율적이다. 그래서 보통 CPU는 I/O작업이 필요하면 일을 맡기고 CPU는 다른 일을 수행하게된다.

일반적으로 인터럽트는 처리하기 위한 소프트웨어가 존재한다. 이를 **Interrupt Service Routine**이라고 하는데, 인터럽트가 발생하면 CPU는 인터럽트를 처리하기 위해 해당 루틴으로 JUMP해서 인터럽트를 처리한다. 

RAM에는 Interrupt Service Routine들의 주소를 저장해놓은 Vector가 존재한다. 이를 Interrupt Vector라고 한다.

Interrupt는 하드웨어에서만 발생하는게 아니다. 소프트웨어에서도 Interrupt를 발생시킬 수 있는데 이를 Trap 또는 Exception이라고 한다. 이는 Error또는 User의 Request를 통해 발생한다.

**운영체제는 Interrupt Driven으로 동작한다.**

### I/O Structure

Process에서 I/O가 필요할때, CPU는 I/O Request를 하고 무엇을 할것인가?

1. I/O가 끝날때까지 CPU를 Wait하고, I/O가 끝나면 재동작하는 방식
2. 아무일도 하지 않는 Loop를 만들어서 동작 (Busy Waiting)
3. I/O가 끝날때까지 다른 프로그램을 동작하고, I/O가 끝나면 프로그램 재시작

**I/O는 CPU에 비해 굉장히 느리다. 그렇기때문에 CPU가 Wait 하는방식은 굉장히 비효율적이기 때문에 1번, 2번 방식은 사용하지 않는다.** 

### Main Memory

Main Memory란 CPU가 직접 접근할 수 있는 큰 Storage 장치이다. 

- Random Access : 메모리에 어느 위치에 접근하든지간 접근속도는 동일하다.
- Volatile : 휘발성 저장 장치이다.

Main Memory는 Random Access Memory라고 해서 줄여서 RAM이라고 불린다.

### Secondary Memory

큰 용량을 제공하는 저장 장치로, 비 휘발성이고 용량이 크다. 예전에는 자기 디스크를 많이 이용했지만 요즘에는 SSD라는 전자식 드라이브를 이용하여, 속도면에서 많은 효율을 얻고 있다.

### Memory Hierarchy

저장장치는 계층화 되어있다. 

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled.png](../assets/os_memory_hierarchy.png)

일반적으로 저장장치는 크게 접근 속도, 용량, 휘발성 3가지 특성을 이용하여 분류할 수 있다. 메모리 계층구조 위에서 아래로 향할 수록 데이터에 대한 접근시간이 길어지지만, 용량은 커진다.
MainMemory까지는 Volatility를 가지며, 그 아래로는 None-Volatility이다.

Cache란 컴퓨터 시스템의 여러곳에서 사용되는 기술로, 자주 사용되거나 최근에 사용된 데이터를 복사하여 저장하고, 이 후에 더 빠른속도로 데이터에 접근할 수 있게 해주는 기술이다. 메모리 계층구조에서 Cache는 레지스터와 RAM사이에 존재한다.

### Direct Memory Access

I/O속도가 매우 빠른 장치의 경우 Interrupt가 빈번하게 발생한다. CPU는 Interrupt가 발생하면, Interrupt를 처리해야하므로, 빈번하게 발생하는 상황에 대해서 CPU는 자기가 할 일을 제대로 하지 못 할 수 있다. 그래서 나온것이 **DMA(Direct Memory Access)**이다. DMA는 Device들이 메모리에 직접 접근하여 읽거나 쓸 수 있도록 하는 기능을 의미하는데 여기서 중요한 것은 CPU가 이 과정에 개입하지 않는다는 것이다.

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%201.png](../assets/os_dma.png)

DMA를 이용해서, CPU가 해야할 일을 대신 처리하게 되면서, CPU의 효율을 늘리고 DMA는 데이터의 전송이 종료되었을때 1 Block 데이터의 단위로 CPU에게 Interrupt를 걸게 된다. 이는 결과적으로 CPU가 받는 Interrupt의 횟수를 줄이게 된다.

### MultiProcessing System

멀티 프로세싱 시스템은 여러개의 프로세서가 버스 때때로는 클락, 메모리를 공유하는 시스템이다. 이러한 시스템의 장점은 다음과같다.

- 처리량이 향상된다.

    프로세서의 수가 많아짐으로써, 적은 시간내에 더 많은 일을 처리할 수 있게된다. 하지만 프로세서가 N배 된다고해서 처리량이 N배가 되는것은 아니다. 다수의 프로세서가 협력하면서 생기는 오버헤드가 존재하기 때문이다.

- 경제적이다

    멀티 프로세싱 시스템은 다수의 싱글 프로세싱 시스템보다 경제적이다. 

- 안정성이 높아진다.

    몇개의 프로세서가 분산되어 일을 처리하기 때문에 한개의 프로세서가 고장나도, 전체 시스템이 중단되지는 않는다. 단지 느려질뿐이다. 

멀티 프로세싱 시스템은 2가지 타입이 존재한다.

- Asymmetric Multiprocessing (비대칭 멀티 프로세싱)

    각 프로세서가 특정한 일만 처리한다. 예를들면 Boss 프로세서는 시스템과 관련된 일을 처리하고, 다른 프로세서들은 미리 정의된 일만 처리하는 방식이다.

- Symmetric Multiprocssing (대칭 멀티프로세싱)

    일의 구분없이 프로세서들이 일을 처리한다. 

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%202.png](../assets/os_multiprocessing_system.png)

## 운영체제가 하는 역할

### Job Scheduling

MultiProgramming 이란 메인 메모리에 여러 작업을 두고 I/O가 일어날때마다 다른 작업을 실행하는 방식이다. CPU는 동시에 한개의 작업만 실행할 수 있기 때문에 한 작업만 계속 실행해서는 안된다. 그렇기 때문에 I/O가 발생할때마다 다른 작업을 선택하는데 이는 운영체제가 Job Scheduling을 통해 선택하게 된다.

### Dual Mode

운영체제는 Mode Bit을 통해 OS를 다른 시스템으로부터 보호한다. User Mode와 Kernal Mode가 존재하며, Mode bit을 이용하면 시스템이 현재 User Code를 실행하는지, Kernal Code를 실행하는지 알 수 있다. 또한 몇가지 명령같은 경우 Kernal Mode의 권한으로만 실행할 수 있는 경우도 존재한다. System Call이 그러한데, System Call 을 하기 위해서는 Mode bit를 커널로 해야하고, 이후에 종료되면 다시 User모드로 되돌린다.

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%203.png](../assets/os_dualmode.png)

### Process Management

프로세스란 프로그램이 실행중인 상태이다. 프로그램은 정적인 객체이며, 프로세스는 동적인 객체라고 생각할 수 있다. 프로세스는 자신의 일을 수행하기 위해 운영체제로부터 CPU와 메모리등을 할당받아서 자신의 일을 처리한다. Single Thread 프로세스 같은 경우 한가지의 Program Counter라는게 존재하는데 이것은 다음번에 실행할 명령어의 주소를 가르킨다. 만약 Multi Thread 프로세스라면 Thread 당 Program Counter가 생기게된다.

운영체제는 프로세스 생명주기를 관리한다. 시스템 프로세스를 생성하고 죽이거나, 중지하거나 재개한다. 또한 프로세스에게 동기화, 통신, DeadLock Handling 매커니즘을 제공하기도 한다.

### Memory Management

프로그램이 실행되기 위해서는 모든 명령 또는 데이터는 Main Memory에 존재해야한다. 운영체제는 어떤 프로세스가 어떤 메모리를 사용하는지 추적하고 프로세스가 필요한 만큼 메모리의 할당, 해제를 담당한다.

### File System Management

운영체제는 파일 시스템을 관리한다. 파일이나 폴더를 만들거나 삭제할 수 있으며, 파일에 대해 읽고 쓰는 기본적인 연산을 지원한다. 또한 파일을 백업할 수 있어야한다.

### Disk Management

운영체제는 디스크 공간을 할당하고, 디스크 읽기, 쓰기 요청을 스케줄링한다. 또한 캐시와 관련된 문제에서 HardDisk, RAM, Cache의 서로 같은 정보의 내용이 다르게 존재한다면 누가 최신의 정보인가를 처리해야한다. 이것을 Cache Coherence라고 한다.



# Process

프로세스란 동적으로 실행되는 프로그램을 의미한다. 

프로세스는 크게 Stack 영역, Heap 영역, Data 영역, Text영역으로 분리된다.

**Text영역은** 프로세스가 실행할 코드가 기계어 형태로 저장된 공간이다. 운영체제가 Text 영역을 보호하기 때문에 수정할 수 없다.

Self Modifing Code와 같은 기법은 런타임에 Text 영역에 기계어 코드를 직접적으로 작성하여, 프로그램의 실행명령을 바꾼다. 운영체제에 메모리에 대한 READ, WRITE, EXECUTE 권한을 **mprotect()**라는 System Call을 요청하여 얻을 수 있다.

**Data영역은** 코드에서 선언한 전역변수, Static 변수 등등이 저장된 공간이다.

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%204.png](../assets/os_process_memory.png)

프로세스에서 **Stack 영역은** 일반적으로 위에서 아래로 할당된다. 보통 프로그램은 컴파일 타임에 선언된 변수를 확인하여, Stack의 크기를 결정한다. 

보통 Procedure를 실행하게 되면 한개의 **Activation Record**가 생기는데 이는 프로시저가 호출되면 Stack 영역에 한개씩 쌓이게 되고, Procedure가 종료되면 사라지게 된다. Activation Record는 프로시저의 실행에 필요한 데이터들을 관리한다.

Heap영역은 프로세스에서 필요할때마다 동적으로 할당받을 수 있는 메모리 영역이다. 즉 Heap의 사용량은 Runtime에 결정된다. 일반적으로 malloc()과 같은 System Call을 이용하면 Heap 영역의 메모리를 얻어서 사용할 수 있다. Heap 영역은 할당받고 사용을 완료했으면 반드시 메모리를 해제해야한다. 그렇지않으면 **Memory Leak (메모리 누수)**가 발생한다.

### Life Cycle

프로세스는 살아생전 총 5개의 상태를 가지게 된다.

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%205.png](../assets/os_process_lifecycle.png)

- new : 프로세스가 처음 만들어진 상태
- ready : cpu를 운영체제로부터 할당받기전 대기중인 상태
- running : 명령이 실행중인 상태
- waiting : 어떤 사건 or I/O를 기다리고 있는 상태
- terminated : 프로세스가 종료된 상태

### Process Control Block

프로세스 제어 블록 일명 PCB는 프로세스의 관련 정보를 저장하는 구조체이다. 

일반적으로 Process의 Context Switching이 일어나면, 실행중인 프로세스 정보를 PCB에 기록하고, 기다리고 있던 다른 프로세스의 PCB를 읽어 해당 프로세스를 실행한다.

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%206.png](../assets/os_process_pcb.png)

## Process Scheduling

CPU는 한정적인 하드웨어 자원이고, 운영체제는 어떤 프로세스에게 CPU를 할당할 것인지, 선택해야한다. 

일반적으로 스케줄링을 하기 위해서 여러개의 큐가 존재한다.

- Job Queue : Disk에서 Ready 상태로 가기전 프로세스들이 존재하는 Queue이다.
- Ready Queue : Memory에서 CPU를 받기 위해 기다리는 프로세스들이 존재하는 Queue이다.
- Device Queue : Device Controller에 존재하는 Queue이다. 프로세스들이 I/O장치를 이용하기 위해 대기한다.

### Long Term Scheduling

JobQueue에서 Ready Queue로 Job을 가져오는 Schduler이다. 이름 그대로 긴 주기를 가지고 한번씩 실행되며, 메모리에 있는 작업의 개수를 조절한다. 

### Short Term Scheduling

Ready중인 프로세스에게 CPU를 할당하는 스케줄러이다. 자주실행되며 매우 빨라야 한다.

### Type of Process

프로세스는 주로 작업하는 종류에 따라 2가지로 분류된다.

- I/O Bound Process : I/O 중심의 프로세스
- CPU Bound Process : CPU 중심의 프로세스

좋은 시스템 성능을 위해서는 I/O 중심의 프로세스와 CPU 중심의 프로세스를 Long - Term Scheduler가 적절히 선택해야 한다.

### Medium Term Scheduler

여러명의 사용자가 여러 프로세스를 실행시켜서 메인 메모리가 부족해진다면, 작업중인 일부의 프로세스를 디스크로 내려보내고 여유가 생기면 다시 올려서 실행한다. 이를 **Swapping**이라고 한다.

### Process의 생성과 종료

프로세스간 부모 자식 관계를 선으로 표시하면 Tree가 만들어 진다.

프로세스를 생성할때 Resource Sharing Option을 선택할 수 있다.

1. 모든 자원을 공유한다.
2. 일부 자원만 공유한다.
3. 공유하지 않는다.

또한 실행 Option을 선택할 수 있다.

1. 부모 자식 프로세스를 동시에 실행한다.
2. 자식 프로세스가 종료할때까지 부모 프로세스가 대기한다.

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%207.png](../assets/os_process_hierachy.png)

보통 프로세스는 Fork() 시스템 콜로 탄생하여, Exit() 이라는 시스템콜로 종료된다. 하지만 부모 프로세스가 abort() 시스템 콜을 이용하여 강제 종료 시킬 수 있다.

일반적으로 자식 프로세스는 부모 프로세스가 없으면 실행이 되지 않는다. 이때 2가지 전략이 존재한다.

1. 부모가 사라지면 모든 자식프로세스가 종료된다. (CasCade Termination)
2. 다른 프로세스의 양자로 들어간다.

만약 부모가 자식 프로세스의 종료를 기다리지 않고 있으면 PCB를 반납할 수 없다. 이는 좀비 프로세스를 생성하게 된다. 또한 이러한 상황에서 부모 프로세스가 종료된다면, 이때 자식 프로세스를 고아 프로세스라고 한다.

### Interprocesses Communication (프로세스간 통신)

우리는 실제로 프로그램을 동작시킬때 한개의 프로세스만 수행되지 않는 경우도 존재한다. 상황에 따라서 여러개의 프로세스가 협력해야하는 케이스가 많이 존재하며, 이때 협력하기 위해서 프로세스간 통신하는 방법이 필요하다. 보통 2가지 방법이 존재한다.

1. **Shared Memory**
   보통 Shared Memory는 공유메모리를 의미한다. Process끼리 공유하는 메모리가 존재하고, 이에 대해 접근할 수 있는것이다.
   보통 프로세스간 통신은 생산자와 소비자가 존재한다. 만약 Shared Memory가 무한하다면, 생산자는 Memory가 부족하다는것을 인지하지 못하고 계속해서 Message를 생산할 것이다. 하지만 Shared Memory는 유한하다. 그렇기 때문에 Producer - Consumer 문제가 발생한다.
   이러한 문제는 원형 Linked List를 이용하여 해결할 수 있다. 공유메모리에 접근할때 발생하는 동기화 문제는 프로세스끼리 알아서 잘해결해야한다. 즉 아래의 코드에서 in과 out은 상호배제이다. 

    ```java
    //Producer
    while(in + 1 == out) 
    	donothing //기다린다.
   
    //Consumer
    while(in == out)
    	donothing // 기다린다.
    ```

2. **Message Passing**
   프로세스간 동기화와 통신을 하기 위해서 사용한다. 

    - 직접 통신

      프로세스간 직접적으로 링크가 구성된다. 
      send(P, message) : P에게 메시지를 보낸다.
      receive(Q, message) : Q로부터 메시지를 받는다.

      ![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%208.png](../assets/os_message_passing_direct.png)

    - 간접 통신

      중간에 Mail Box를 두고 이곳에 메시지를 작성하고 읽어가는 방식으로 작동한다. Mail Box는 고유 Id가 존재한다. 이 방식은 여러개의 프로세스가 접근할 수 있고, Mail Box 자체를 여러개 생성하여 여러 링크를 구성할 수 있다.

      ![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%209.png](../assets/os_message_passing_indirect.png)

3. **PIPE**

   파이프 또한 IPC 방법 중 하나이다. 파이프는 프로세스간 데이터를 주고 받는 통로를 의미한다.

   - Ordinary Pipe (익명 파이프)

     부모-자식 관계에서 데이터를 일방적으로 전달한다.

   - Named Pipe(이름있는 파이프)

     부모관계가 아니여도 양방향으로 데이터를 교환할 수 있다.

4. **Socket**

   컴퓨터 간 통신을 할때 사용한다. Socket이란 IP와 Port를 합친것을 의미한다. 

5. **RPC (Remote Procedure Call) 프로세스간 추상화된 프로시저 콜**

   Data는 기계에 따라서 Big-Endian 또는 Littel-Endian으로 나타나기때문에 기계에 종속적이다. 이때 이 Data를 기계에 독립적으로 변환하는것을 Marshalling이라고 한다. 
   RPC의 사용자는 다른 컴퓨터의 위치와 포트번호를 이용하여, RPC 메세지를 작성하고 데이터를 전송한다 이후 메서드 실행결과를 상대측으로부터 전달받는다.



# Thread

Thread는 CPU를 이용하기 위한 가장 기본적인 단위로, Thread ID, Program Counter, Register Set, Stack을 가지며, 다른 Thread들과 Code, Data, 자원들을 공유한다. 전통적인 프로세스는 프로세스당 한개의 스레드를 사용했지만, 만약 여러개의 스레드를 사용하게 된다면 단위시간당 처리량을 향상할 수 있게 된다. 이를 멀티 스레드 프로그램이라고 한다. 이 경우 스레드는 서로 독립적인 작업을 수행해야하기 때문에, 각자의 Stack과 Register Set을 가지게 된다.

**Thread는 한개의 독립적인 실행흐름이다.** 보통 Stack이라는 영역에는 함수 인자, 리턴 주소, 함수내 선언된 변수들 등등 실행흐름에 따른 변수들이 저장된다. 그렇기 때문에 Thread는 자신만의 Stack영역을 가지고 있어야한다.

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%2010.png](../assets/os_thread.png)

**멀티 스레드의 장점은 다음과 같다.**

- Responsiveness : 응답성이 개선된다. 단위시간당 처리량이 향상되기 때문에 사용자가 더욱 빨리 응답을 받을 수 있게된다.
- Resource Sharing : 데이터와 자원을 공유하기 때문에 메모리를 효율적으로 사용할 수 있으며, 데이터를 주고받는 과정이 쉽다.
- Economy : 쓰레드간 Context Switching은 프로세스보다 훨씬 비용이 적게 들면서 더 빠르게 동작한다.
- Scalability : 멀티 코어 시스템에서 많은 이점을 얻을 수 있다.

**멀티 스레드의 단점은 다음과 같다.**

멀티 쓰레드는 프로세스 내에서 자원을 공유하기 때문에 동일한 자원을 동시접근할때는 조심해서 프로그래밍 해야한다. 즉 Data Race현상이 발생할 수 있고, 쓰레드가 이상한 값을 읽어들일 수 있다. 이는 동기화 작업을 통해 처리할 수 있다. 공유자원을 접근할때 쓰레드가 순차적으로 접근할 수 있게하는 방법인데 이는 Bottle neck (병목현상)을 일으킬 수 있으므로 이 또한 조심해야한다.

**멀티 프로세스 vs 멀티 쓰레드**

멀티 쓰레드는 멀티 프로세스에 비해 가볍고, 프로세스 내의 데이터를 공유하기 때문에 메모리 부분에서도 많은 이점을 챙길 수 있다. 또한 Context Switching이 빠르고, 캐시를 초기화할 필요도 없다.
멀티 프로세스는 멀티 스레드에 비해 무겁고, 프로세스간 메모리가 분리되어있다. 또한 Context Switching시에 지금까지 쌓은 캐시가 쓸모가 없어지기 때문에 초기화한다. 즉 Cache Miss가 발생한다.

그렇다고 멀티 쓰레드가 더 좋다는 뜻은 아니다. 멀티쓰레드는 어떤 특정한 쓰레드의 비정상 종료시 프로세스내 모든 쓰레드에게 영향을 끼칠 수 있지만, 멀티 프로세스는 특정한 프로세스가 죽는다고 해서 다른 프로세스에게 영향을 미치지 않는다. 

또한 멀티 쓰레드는 메모리를 공유하기 때문에 메모리의 접근을 Lock을 통해 통제할 필요가 있는데, 멀티 프로세스는 애초에 메모리가 분리되어있으므로 그럴 필요가 없다. 단 공유메모리를 사용한다면 똑같은 문제가 발생한다.

멀티쓰레드는 쓰레드간 데이터의 통신이 굉장히 간편하다. 메모리에 데이터를 작성하면 다른 쓰레드가 메모리를 읽어서 가져가면 된다. 하지만 멀티 프로세스는 IPC를 통해 프로세스간 데이터를 주고받아야한다. 이는 더 복잡하다.

### Concurrency(병행성) vs Parallelism(병렬성)

병행성은 A작업과 B작업이 같이 진행되는것을 의미한다. 이것은 단일 쓰레드에서도 CPU의 문맥교환이 빠르게 동작하면서, 병행성을 얻을 수 있다.

병렬성이란 어떤 작업이 동시에 실행되는것을 의미한다. (멀티 쓰레드, 멀티 프로세스)

### User Thread 와 Kernel Thread

Thread는 2가지 종류가 존재한다. User Level에서 제공되는 User Thread와 Kernal Level에서 지원되는 Kernel Thread이다. 결국에는 User Thread는 Kernel Thread와 연결되어야 실행될 수 있다. 

1. **Many To One Model**
   여러개의 유저 쓰레드가 한개의 커널 쓰레드에게 연결된다. 이 방법은 문제가 있는데, 특정한 유저 쓰레드가 Blocking System Call을 이용하면 Kernel Thread는 Blocking되고, 다른 Thread들은 실행될 수 없다. 이는 병렬성에 좋지 않기 때문에 많이 사용되지 않는다.

2. **One To One Model**

   한개의 유저 쓰레드당 한개의 커널 쓰레드에게 연결된다. 이 모델은 유저 쓰레드가 한개 생성될때마다, 커널 쓰레드가 한개 생성되어야 하기 때문에 컴퓨터에게 매우 부담이 크다. 요즘에는 컴퓨터가 좋아져서 사용할 수 있는 모델이다.

3. **Many To Many Model**

   이 모델은 Kernal Thread가 User Thread들의 수보다 적거나 같은 숫자로 구성된다. 미리 Kernal Thread의 숫자를 특정해놓을 수 있으며, Many To One보다 더 좋은 병렬성을 확보할 수 있다.

# CPU Scheduler (Short Term Scheduler)

Ready Queue에 있는 프로세스에게 CPU를 할당한다. 보통 다음과 같은 경우 Scheduler가 동작한다.

- 프로세스가 I/O작업을 시작할때 (**비 선점**)
- 프로세스가 자신의 모든 CPU 할당 시간을 사용했을때 (**선점**)
- 새로 ReadyQueue들어온 프로세스에게 CPU를 줄것인지 (**선점**)
- 프로세스가 종료되었을때 (**비 선점**)

선점 알고리즘이란 프로세스가 자발적으로 중단하는게 아닌, 운영체제가 CPU를 강제로 빼앗는 경우이다. 이럴때 주의해야할 점은 프로세스가 Critical Section을 실행중인가에 대한 여부이다. Critical Section에서 프로세스가 중단되면 비일관성 확률이 높아진다.

### Dispatcher

Dispatcher는 실제로 CPU에게 프로세스를 할당하는 역할로, OS의 일부이다. 다음과 같이 동작한다.

1. Process Context를 교환한다.
2. UserMode로 변경한다. (Dispatcher는 Kernel Mode에서 동작하기 때문이다.)
3. ProgramCounter가 저장하고 있던 명령어로 분기하여 프로그램을 실행한다.

Dispatcher는 위와 같이 동작하는데 사실 위에서 동작하는것은 오버헤드에 해당한다. 위의 과정을 실행하는데 걸리는 시간을 Dispatcher Latency라고 한다.

## Scheduling Algorithm

### FCFS (First Come, First Served)

ReadyQueue에 들어온 프로세스 순서대로 처리한다. 이는 비 선점형 (No Preemptive) 스케줄링이며,  프로세스가 CPU를 잡으면 CPU Burst가 끝날때까지 CPU를 반환하지 않는다. 할당되었던 CPU가 반환될 때만 스케줄링이 발생한다.

**Convey Effect(호위함 효과)가 발생한다.**

Convey Effect : 대체적으로 짧은 프로세스가 긴 프로세스 뒤로 오게되는 현상

### SJF (Shortest Job First)

ReadyQueue에 존재하는 CPU Burst 시간이 가장 적은 프로세스를 우선 실행한다. ⇒ 다른 프로세스들의 대기시간이 최적화된다. **하지만 어떻게 CPU Burst Time을 알아낼 수 있는가?**

프로세스의 과거행동을 가지고 측정한다. 

$E(n + 1) = a * T(n) + (1 - a) * E(n)$  E(n) = 예측시간, T(n) = 실제 걸린 시간

SJF는 Starvation(기아 현상)이 발생할 수 있다. 즉 CPU Burst가 긴 프로세스의 경우 다른 프로세스들에게 밀려서 실행되지 못할 가능성이 있다.

### SRTF(Shortest Remaining Time First)

새로운 프로세스가 도착할 때마다 스케줄링이 일어난다. 선점형 (Preemptive) 스케줄링이며, 현재 수행중인 프로세스의 남은 Busrt Time보다 더 짧은 Burst Time을 가진 프로세스가 도착하면, CPU를 뺏긴다.

이 또한 Starvation이 발생할 수 있다.

### Priority Scheduling

우선순위가 가장 높은 프로세스에게 CPU를 할당하는 스케줄링이다. SJF 또한 가장 CPU Burst가 짧은 프로세스에게 CPU를 할당하므로 Priortiy Scheduling의 한 방법이라고 생각할 수 있다.

우선순위 스케줄링 방식의 문제는 우선순위가 낮은 프로세스가 Starvation 현상에 직면할 수 있다는 사실이다. 보통 이런 방법은 **Aging** 이라는 방식으로 해결한다.

Aging : 프로세스가 오래 기다리면 우선순위를 높혀주는것

- 선점형 스케줄링 방식

  우선순위 스케줄링을 선점형으로 사용한다면, 더 높은 우선순위 프로세스가 도착할때 실행중인 프로세스를 종료하고 CPU를 선점한다.

- 비선점형 스케줄링 방식

  우선순위 스케줄링을 비선점형으로 사용한다면, 높은 우선순위 프로세스를 Ready Queue의 Head에 둔다.

**비선점형 알고리즘들은 프로세스가 자발적으로 CPU를 내놓지 않는 경우 CPU를 오랫동안 가지고 있게 된다. 이는 여러 사람이 컴퓨터를 이용할 경우 좋지 않은 방법이다.**

### Round Robin (RR)

이 방식은 돌아가면서 CPU를 사용할 수 있는 스케줄링이다. 

각 프로세스에게 실행할 수 있는 시간 (Time Quantum) q를 주고 이 시간이 지나도, CPU를 반납하지 않는다면 선점하여 다른 프로세스에게 CPU를 제공한다. 
이는 전체 프로세스가 N가 일때 한개의 프로세스가 최대 기다리는 시간이 (N - 1)* q 를 넘지 않는다는 뜻과 동일하다.

Time Quantum은 적절하게 선택되어야 한다. 너무 큰 경우에는 거의 FCFS와 같은 알고리즘이다. 또한 너무 작은 경우에는 Context Switching이 너무 자주 발생하여, 이로인한 오버헤드가 많이 발생한다.

### Multi Level Queue

Ready Queue를 여러개 두고 작업의 종류에 따라 Ready Queue가 달라진다. 예를들어 ForeGround Ready Queue(Interactive)와 Background Ready Queue(Batch)가 존재하는데, 사용자와의 Interactive가 더 중요하다면 ForeGround Ready Queue의 프로세스들을 먼저 실행한다. 하지만 이는 Starvation이 발생할 수 있기 때문에 일반적으로 Queue마다 우선순위를 두고, 우선순위에 따라 CPU시간을 분할하여, Queue들에게 제공한다.

**Multi Level FeedBack Queue**

이 큐는 프로세스가 Queue간에 이동할 수 있는 방식이다. 프로세스가 너무 오래 기다리면, 상위 Queue로 승진시켜 실행하는 방식이다. 이 방식은 승진정책, 강등정책, 큐의 개수 등등 고려해야할 것이 많다.

# 프로세스 동기화

데이터 일관성을 유지하기 위해서는 협력하는 프로세스간 순차적인 실행을 보장해야한다. 

보통 두개의 프로세스가 동시에 공유메모리에 접근할때 Race Condition이 발생한다. 누가 먼저 메모리에 접근하냐에 따라 결과가 뒤바뀐다.

Race Condition : 명령어의 순서에 따라 결과가 뒤바뀌는것! 이것은 데이터의 비일관성을 초래한다.

### Critical Section (임계 구역)

여러개의 협력하는 프로세스가있을때 공유메모리에는 하나의 프로세스만 접근해야한다. 동일한 자원에 동시에 접근하는 작업을 실행하는 코드 영역을 임계 구역이라고 한다.

**임계구역 문제 해결 방안.**

1. Mutual Exclusion (상호 배제) 단 하나의 프로세스만 임계구역에 접근할 수 있다.
2. Progress (진행 조건) 임계구역에 들어가고자 하는 프로세스를 무한정 대기 시킬 수 없다. 만약 Critical Section을 차지하고 있는 프로세스가 없다면 진행해야한다.
3. Bounded Wait(한계 대기) 임계구역에 들어가고자 할때 언젠가는 임계구역에 들어가야 한다.

**Peterson's Solution (현실적이지 못하고 쓸모없지만, 소프트웨어만으로 임계구역을 처리하기 때문에 의의가 있음. 최근 CPU는 명령어의 순서를 바꾸므로 사용불가)**

```java
#Process 1
int turn;
boolean flag[2];
do {
	flag[1] = true
	turn = 2
	while(flag[2] && turn == 2); 
	
	//Start
	//Critical Section
	//End
	flag[1] = false;
}

#Process 2
int turn
boolean flag[2];
do {
	flag[2] = true;
	turn = 1;
	while(flag[1] && turn == 1);
	
	//Start
	//Critical Section
	//End

	flag[2] = false;
}
```

### 동기화를 위해 하드웨어가 지원하는 Atomic 연산

1. test_and_set()을 이용한 Spin Lock

```java
while(test_and_set(&lock) == 1); 
//Start
//CriticalSection
//End
lock = 0;
```

test_and_set의 lock이 1이라면 누군가가 임계구역에 접근중인것이다.
test_and_set의 lock이 0이라면 임계구역에 접근한다.

2. compare_and_swap()을 이용한 Spin Lock
   compare_and_swap 함수는 두번째 인자로 Expected Value, 세번째 인자로 New_Value를 주고, 리턴값으로 이전의 값을 반환한다. 리턴값이 0이라면 이전의 값이 0이였다는 의미로 임계구역에 접근한다.

```java
while(compare_and_swap(&lock, 0, 1) != 0);
//Start
//CriticalSection
//End
lock = 0;
```

### Mutex Locks (뮤텍스)

뮤텍스란 Mutual Exclusion(상호배제)의 약자로 임계구역을 쉽게 이용하기 위해 만든것이다.

뮤텍스는 Lock을 얻는 방법, Lock을 해제하는 방법 2가지의 연산을 제공하는데, 이 두개의 연산은 모두 Atomic하게 연산되야 한다.  

```java
do {
	acquire();
	//Critical Section
	release();
}while(true)

acquire(){
	while(!available);
	available = false;
}

release() {
	available = true;
}
```

위의 코드가 바로 뮤텍스를 구현한 예이다. 이때 acquire()함수와 release() 함수는 원자적으로 실행되어야 한다.

### Semaphore (세마포어)

세마포어는 int형 변수이다(S). 단 이 변수가 사칙연산을 제공하기 위해 int형 변수인것이 아니다. 세마포어는 2가지 연산 wait()과 signal()을 제공한다. 두개의 함수 모두 Atomic하다.

```java
wait(S) {
	while(S <= 0);
	S--;
}

signal(S) {
	S++:
}
```

세마포어는 2가지 종류( Counting Semaphore, Binary Semaphore) 가 존재한다. 차이는 세마포어가 어떤값을 가질 수 있냐에 따라 갈리는데, Counting은 아무 정수 값이나 가능하며, Binary는 0 또는 1만 가능하다. Binary Semaphore는 사실 Mutex와 동일하다.

위와 같은 방식은 사실 Busy Waiting이기 때문에 성능에 좋지 않다. 다른방법으로도 구현이 가능한데, 방식은 큐를 이용하는것이다. 누군가 세마포어에 접근할때 이미 사용하고 있으면 자신의 실행흐름을 Block하고 대기한다.

이후에 임계구역을 차지하고 있는 프로세스가 자신의 실행을 끝낸뒤, 큐에 있는 프로세스, 쓰레드 중 하나를 Wakeup 한다.

```c
typedef struct {
	int value;
	struct process *list;
}semaphore;

wait(S) {
	S->value--;
	if(S->value < 0){
		//add this process to S->list;
		block();
	}
}

signal(S) {
	S->value++;
	if(S->value <= 0){
		//remove a Process p from S->list;
		wakeUp(p);
	}
}

```

### Monitor

모니터는 Lock을 지원하는 ADT라고 할 수 있다.즉  상호배제가 필요한 함수들의 집합과, 뮤텍스가 묶여있는 ADT이다.

**모니터를 사용하는 가장 대표적인 자바의 예를 들어보자**

모니터는 2개의 큐 (배타동기 Queue, 조건동기 Queue)를 가지고 있다. 
배타 동기 Queue는 한개의 쓰레드가 이미 임계구역을 사용하고 있다면 다른 쓰레드들을 대기시키는 Queue이다.
조건 동기 Queue는 임계구역에서 Wait()메서드를 호출하면 해당 쓰레드를 Block 시키고 다른 쓰레드를 임계구역에서 실행시킨다. 이후 다른 쓰레드가 Notify()메서드를 호출하면 쓰레드가 깨어나서 하던일을 계속 진행하게 된다.

![Operating%20System%20c77ca02659ca4fe0b181cedf9ae51aa2/Untitled%2011.png](../assets/os_monitor.png)

```java
class Ex {
	private int value;
	synchronized void Foo() {}
	synchronized void Bar() {}
	void func(){}
}
```

위의예제에서 Foo메서드와 Bar메서드에 접근하기 위해서는 모니터 락을 얻어야 하며, 위의 두개 메서드는 서로 다른 임계구역이 아닌 서로 같은 임계구역이다. 즉 Foo()메서드가 수행중이라면 다른 쓰레드는 Foo뿐만 아니라 Bar도 사용할 수 없다. 하지만 func() 메서드는 언제든지 호출 할 수 있다.